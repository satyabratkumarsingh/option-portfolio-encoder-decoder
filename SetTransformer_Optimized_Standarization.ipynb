{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satyabratkumarsingh/option-portfolio-encoder-decoder/blob/main/SetTransformer_Optimized_Standarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxGpO-r9tKdO",
        "outputId": "e7c57cae-a2e8-44ba-ef7e-c6ad58f603ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: comet_ml in /usr/local/lib/python3.11/dist-packages (3.49.11)\n",
            "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (0.23.0)\n",
            "Requirement already satisfied: everett<3.2.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet_ml) (3.1.0)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (4.24.0)\n",
            "Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (5.9.5)\n",
            "Requirement already satisfied: python-box<7.0.0 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (6.1.0)\n",
            "Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (2.32.3)\n",
            "Requirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (13.9.4)\n",
            "Requirement already satisfied: semantic-version>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (2.10.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (2.31.0)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.11/dist-packages (from comet_ml) (3.20.1)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (1.17.2)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (3.1.1)\n",
            "Requirement already satisfied: configobj in /usr/local/lib/python3.11/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet_ml) (5.0.9)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.25.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.4->comet_ml) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.4->comet_ml) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.4->comet_ml) (2025.6.15)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.3.2->comet_ml) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.3.2->comet_ml) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml) (0.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema!=3.1.0,>=2.6.0->comet_ml) (4.14.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install comet_ml\n",
        "!pip install tqdm\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xq6f21Ut4gZ"
      },
      "source": [
        "#Mount to Google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZpgcStFt9D_",
        "outputId": "4aee16b2-2a78-4057-85dd-deae433057b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzJ3v98RIsP3"
      },
      "source": [
        "#Deele scalars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FlWdxvE-Iv8T"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def delete_file_from_drive(full_file_path):\n",
        "  if os.path.exists(full_file_path):\n",
        "      try:\n",
        "          os.remove(full_file_path)\n",
        "          print(f\"File '{full_file_path}' successfully deleted from Google Drive.\")\n",
        "      except Exception as e:\n",
        "          print(f\"Error deleting file '{full_file_path}': {e}\")\n",
        "  else:\n",
        "      print(f\"File '{full_file_path}' not found at '{full_file_path}'.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ki0SZxceuP2P"
      },
      "source": [
        "# Portfolio Generation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hBQ4QTavtSMn"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import itertools\n",
        "from itertools import product\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gc # For garbage collection\n",
        "\n",
        "# Parameters\n",
        "MU = 0.05\n",
        "SIGMA = 0.2\n",
        "T = 1.0 # Time to maturity\n",
        "NOISE_STD = 0.01\n",
        "MIN_PRICE_RANGE = 100\n",
        "MAX_PRICE_RANGE = 1000\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def generate_option_prices_for_idx(idx, n, weights=None):\n",
        "    # Use numpy's default_rng for better random number generation and seeding\n",
        "    rng = np.random.default_rng(idx)\n",
        "    # Use torch.manual_seed for PyTorch operations\n",
        "    torch.manual_seed(idx)\n",
        "    if DEVICE.type == 'cuda':\n",
        "        torch.cuda.manual_seed_all(idx)\n",
        "\n",
        "    # Generate S_0\n",
        "    random_number = rng.integers(MIN_PRICE_RANGE, MAX_PRICE_RANGE + 1) # +1 because randint is inclusive\n",
        "    min_price = random_number\n",
        "    max_price = random_number + 5\n",
        "    S_0 = rng.uniform(min_price, max_price)\n",
        "\n",
        "    # Generate option types\n",
        "    option_types = rng.choice([\"call\", \"put\"], size=n)\n",
        "    option_types_numeric = np.where(option_types == \"call\", 1, 0).astype(np.float32) # Ensure float32\n",
        "\n",
        "    # Generate X_prices (strike prices)\n",
        "    K_prices = np.zeros(n, dtype=np.float32) # Ensure float32\n",
        "    for i in range(n):\n",
        "        K_prices[i] = S_0 * rng.uniform(0.90, 1.20)\n",
        "\n",
        "    # Generate or use weights\n",
        "    if weights is None:\n",
        "        # If weights are not provided, generate them using generate_combinatorial_weights_manageable\n",
        "        weight_sets = generate_combinatorial_weights_manageable(n)\n",
        "        weights_array = weight_sets[0]  # Use the first (and only) set of weights\n",
        "    else:\n",
        "        weights_array = np.array(weights, dtype=np.float32)  # Ensure float32\n",
        "\n",
        "    return K_prices, option_types_numeric, S_0, weights_array\n",
        "\n",
        "\n",
        "def generate_combinatorial_weights_manageable(n, base_weights=[-0.75, -0.5, -0.25, 0, 0.25, 0.5, 0.75]):\n",
        "    weight_sets = []\n",
        "\n",
        "    # Handle the case where n < 2\n",
        "    if n < 2:\n",
        "        weights = np.zeros(n, dtype=np.float32)\n",
        "        if n == 1:\n",
        "            # If only one position, assign a long position (1.0)\n",
        "            weights[0] = 1.0\n",
        "        weight_sets.append(weights)\n",
        "        return weight_sets\n",
        "\n",
        "    # Generate a single portfolio: either one long or one short, and the rest from combinatorics\n",
        "    weights = np.zeros(n, dtype=np.float32)\n",
        "\n",
        "    # Randomly choose if we want a long or short portfolio\n",
        "    is_long = random.choice([True, False])\n",
        "\n",
        "    if is_long:\n",
        "        # Choose one position to be long (1.0)\n",
        "        long_idx = random.randint(0, n - 1)\n",
        "        weights[long_idx] = 1.0\n",
        "    else:\n",
        "        # Choose one position to be short (-1.0)\n",
        "        short_idx = random.randint(0, n - 1)\n",
        "        weights[short_idx] = -1.0\n",
        "\n",
        "    # Fill remaining positions with combinatorial weights from base_weights\n",
        "    remaining_positions = [i for i in range(n) if weights[i] == 0]  # Find positions not yet filled\n",
        "    combinatorics = np.random.choice(base_weights, size=len(remaining_positions), replace=True)\n",
        "\n",
        "    # Assign combinatorial weights to the remaining positions without normalization\n",
        "    weights[remaining_positions] = combinatorics\n",
        "\n",
        "    weight_sets.append(weights)\n",
        "\n",
        "    return weight_sets\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "def black_scholes_delta(S, K, T, r, sigma, option_type):\n",
        "    \"\"\"\n",
        "    Computes the Black-Scholes delta for a call or put option.\n",
        "\n",
        "    Args:\n",
        "        S (Tensor): Spot price [any shape]\n",
        "        K (Tensor): Strike price [same shape as S or broadcastable]\n",
        "        T (float or Tensor): Time to maturity (scalar or broadcastable)\n",
        "        r (float or Tensor): Risk-free rate (scalar or broadcastable)\n",
        "        sigma (float or Tensor): Volatility (scalar or broadcastable)\n",
        "        option_type (Tensor): 1 for call, 0 for put [same shape as S]\n",
        "\n",
        "    Returns:\n",
        "        Tensor: Delta of the option [same shape as S]\n",
        "    \"\"\"\n",
        "    eps = 1e-8  # Numerical stability for sqrt\n",
        "    device = S.device\n",
        "\n",
        "    T = torch.as_tensor(T, device=device, dtype=S.dtype)\n",
        "    r = torch.as_tensor(r, device=device, dtype=S.dtype)\n",
        "    sigma = torch.as_tensor(sigma, device=device, dtype=S.dtype)\n",
        "\n",
        "    d1 = (torch.log(S / K + eps) + (r + 0.5 * sigma ** 2) * T) / (sigma * torch.sqrt(T + eps))\n",
        "\n",
        "    # More stable, recommended: torch.special.ndtr(d1) (if available)\n",
        "    N_d1 = torch.distributions.Normal(0.0, 1.0).cdf(d1)\n",
        "\n",
        "    delta = torch.where(option_type == 1, N_d1, N_d1 - 1.0)\n",
        "    return delta\n",
        "\n",
        "\n",
        "def compute_cashflow(portfolio, S_T, weights):\n",
        "    strikes = portfolio[..., 0]\n",
        "    types = portfolio[..., 1]\n",
        "    weights = weights.to(DEVICE)\n",
        "\n",
        "    # Compute option payoffs\n",
        "    payoffs = torch.where(\n",
        "        types == 1,\n",
        "        torch.relu(S_T - strikes),\n",
        "        torch.relu(strikes - S_T)\n",
        "    )\n",
        "    weighted_payoffs = payoffs * weights\n",
        "    cashflow = weighted_payoffs.sum(dim=-1, keepdim=True)\n",
        "\n",
        "    # --- Continuous Derivative (Black-Scholes Delta) ---\n",
        "    delta = black_scholes_delta(\n",
        "        S_T, strikes, T=T, r=MU, sigma=SIGMA, option_type=types\n",
        "    )\n",
        "    weighted_delta = weights * delta\n",
        "    derivative = weighted_delta.sum(dim=-1, keepdim=True)\n",
        "\n",
        "    return cashflow.to(torch.float32), derivative.to(torch.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYzXfDU9JFnL",
        "outputId": "f2aff7ca-84a8-4cc1-8eaf-e25dc5a335c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File '/content/drive/MyDrive/Ucl/K_Scalar.pkl' successfully deleted from Google Drive.\n",
            "File '/content/drive/MyDrive/Ucl/S_T_scalar.pkl' successfully deleted from Google Drive.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/Ucl/\"\n",
        "K_SCALAR_FILE = os.path.join(DRIVE_PATH, 'K_Scalar.pkl')\n",
        "ST_SCALAR_FILE = os.path.join(DRIVE_PATH, 'S_T_scalar.pkl')\n",
        "\n",
        "delete_file_from_drive(K_SCALAR_FILE)\n",
        "delete_file_from_drive(ST_SCALAR_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xM4XPMb_uVNO"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iYHA4zC0uKXz"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/Ucl/\"\n",
        "K_SCALAR_FILE = os.path.join(DRIVE_PATH, 'K_Scalar.pkl')\n",
        "ST_SCALAR_FILE = os.path.join(DRIVE_PATH, 'S_T_scalar.pkl')\n",
        "SCALAR_SAMPLE_NO = 80000000\n",
        "\n",
        "\n",
        "\n",
        "class OperatorDatasetStandarization(Dataset):\n",
        "\n",
        "    def __init__(self, num_samples, portfolio_size, num_samples_S_T,\n",
        "                 K_Scalar=None, S_T_scalar=None, cashflow_scaler=None,\n",
        "                 is_fitting_mode=False): # NEW: Add is_fitting_mode\n",
        "\n",
        "        self.num_samples = num_samples\n",
        "        self.portfolio_size = portfolio_size\n",
        "        self.num_samples_S_T = num_samples_S_T\n",
        "        self.is_fitting_mode = is_fitting_mode # Store the mode\n",
        "\n",
        "        # Load or generate K_Scalar and S_T_scalar\n",
        "        if K_Scalar is None or S_T_scalar is None:\n",
        "            if os.path.exists(K_SCALAR_FILE) and os.path.exists(ST_SCALAR_FILE):\n",
        "                print(\"Loading K and S_T scalers from Google Drive...\")\n",
        "                self.K_Scalar = joblib.load(K_SCALAR_FILE)\n",
        "                self.S_T_scalar = joblib.load(ST_SCALAR_FILE)\n",
        "            else:\n",
        "                print(\"Generating and saving new K and S_T scalers to Google Drive...\")\n",
        "                self.K_Scalar, self.S_T_scalar = self._generate_and_save_K_ST_scalers(SCALAR_SAMPLE_NO)\n",
        "                print(\"***** Generated K_Scalar and S_T_Scalar and saved into Google drive\")\n",
        "        else:\n",
        "            self.K_Scalar = K_Scalar\n",
        "            self.S_T_scalar = S_T_scalar\n",
        "\n",
        "\n",
        "        if not self.is_fitting_mode:\n",
        "            if cashflow_scaler is None:\n",
        "                 if os.path.exists(CASHFLOW_SCALAR_FILE):\n",
        "                    print(\"Loading Cashflow scaler from Google Drive...\")\n",
        "                    self.cashflow_scaler = joblib.load(CASHFLOW_SCALAR_FILE)\n",
        "                 else:\n",
        "                    print(\"WARNING: Cashflow scaler not provided and not found on drive. \"\n",
        "                          \"Cashflows will not be normalized. Consider running fitting process.\")\n",
        "                    self.cashflow_scaler = None\n",
        "            else:\n",
        "                self.cashflow_scaler = cashflow_scaler\n",
        "        else:\n",
        "            self.cashflow_scaler = None # No scaler in fitting mode\n",
        "\n",
        "\n",
        "    def _generate_and_save_K_ST_scalers(self, num_samples):\n",
        "        # Your existing code for generating and saving K_Scalar and S_T_scalar\n",
        "        S_0_values = np.random.uniform(MIN_PRICE_RANGE, MAX_PRICE_RANGE, num_samples)\n",
        "        K_prices = S_0_values * np.random.uniform(0.90, 1.20, num_samples)\n",
        "\n",
        "        Z = np.random.randn(num_samples) # One random shock per S_T value\n",
        "        S_T_values = S_0_values * np.exp((MU - 0.5 * SIGMA**2) * T + SIGMA * np.sqrt(T) * Z)\n",
        "\n",
        "        K_scalar = MinMaxScaler()\n",
        "        K_scalar.fit(K_prices.reshape(-1, 1))\n",
        "\n",
        "        S_T_scalar = MinMaxScaler()\n",
        "        S_T_scalar.fit(S_T_values.reshape(-1, 1))\n",
        "\n",
        "        # Save the scalers\n",
        "        joblib.dump(K_scalar, K_SCALAR_FILE)\n",
        "        joblib.dump(S_T_scalar, ST_SCALAR_FILE)\n",
        "\n",
        "        return K_scalar, S_T_scalar\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Generates and returns a single data sample (portfolio, S_T, cashflow, derivative).\n",
        "        This method is called by the DataLoader.\n",
        "        \"\"\"\n",
        "\n",
        "        K, option_types, S_0, weights = generate_option_prices_for_idx(\n",
        "            idx, self.portfolio_size\n",
        "        )\n",
        "\n",
        "        portfolio_features_tensor = torch.stack([\n",
        "            torch.tensor(K, dtype=torch.float32, device=DEVICE),\n",
        "            torch.tensor(option_types, dtype=torch.float32, device=DEVICE),\n",
        "            torch.tensor(weights, dtype=torch.float32, device=DEVICE)\n",
        "        ], dim=-1)\n",
        "\n",
        "        weights_i = torch.tensor(weights, dtype=torch.float32, device=DEVICE)\n",
        "        K_i = torch.tensor(K, dtype=torch.float32, device=DEVICE)\n",
        "        S_0_i = torch.tensor(S_0, dtype=torch.float32, device=DEVICE)\n",
        "        Z = torch.clamp(torch.randn(self.num_samples_S_T, device=DEVICE), -3, 3)\n",
        "\n",
        "        S_T_i = S_0_i * torch.exp((MU - 0.5 * SIGMA**2) * T + SIGMA * torch.sqrt(torch.tensor(T, device=DEVICE)) * Z)\n",
        "        S_T_i += torch.randn_like(S_T_i, device=DEVICE) * (NOISE_STD * S_T_i)\n",
        "\n",
        "        # Normalization for K and S_T (always apply if scalers are present and not in fitting mode)\n",
        "        # Note: In fitting mode, K and S_T are still generated, but their *normalized* versions\n",
        "        # are not what we're collecting for the cashflow scaler.\n",
        "        if not self.is_fitting_mode:\n",
        "            K_i_cpu = K_i.reshape(-1, 1).cpu()\n",
        "            K_i_normalized = torch.tensor(self.K_Scalar.transform(K_i_cpu), dtype=torch.float32, device=DEVICE)\n",
        "            S_T_i_normalized = torch.from_numpy(self.S_T_scalar.transform(S_T_i.cpu().numpy().reshape(-1, 1))).to(DEVICE).squeeze()\n",
        "        else: # In fitting mode, just use raw K_i and S_T_i for generating raw cashflow\n",
        "            K_i_normalized = K_i # This won't be used for input features directly, but kept for clarity\n",
        "            S_T_i_normalized = S_T_i\n",
        "\n",
        "\n",
        "        # Compute cashflow and derivative (ALWAYS raw when generated in __getitem__)\n",
        "        cashflow_i_raw, derivative_i_raw = compute_cashflow(\n",
        "            portfolio_features_tensor.expand(self.num_samples_S_T, -1, -1),\n",
        "            S_T_i.unsqueeze(-1),\n",
        "            weights_i.expand(self.num_samples_S_T, -1)\n",
        "        )\n",
        "\n",
        "        # ===== CASHFLOW NORMALIZATION (Apply only if a scaler is provided and not in fitting mode) =====\n",
        "        if self.cashflow_scaler is not None and not self.is_fitting_mode:\n",
        "            # Convert to numpy on CPU for scaler, then back to tensor\n",
        "            cashflow_i_normalized_np = self.cashflow_scaler.transform(cashflow_i_raw.cpu().numpy().reshape(-1, 1))\n",
        "            cashflow_i_to_return = torch.from_numpy(cashflow_i_normalized_np).to(DEVICE).squeeze()\n",
        "        else:\n",
        "            # If no scaler or in fitting mode, return the raw cashflow\n",
        "            cashflow_i_to_return = cashflow_i_raw.squeeze()\n",
        "\n",
        "        # Update portfolio_i_normalized with normalized K_i if not in fitting mode\n",
        "        if not self.is_fitting_mode:\n",
        "            portfolio_i_normalized = portfolio_features_tensor.clone()\n",
        "            portfolio_i_normalized[:, 0] = K_i_normalized.squeeze()\n",
        "        else: # In fitting mode, just return original K in portfolio_features_tensor for now\n",
        "            portfolio_i_normalized = portfolio_features_tensor.clone()\n",
        "\n",
        "\n",
        "        return portfolio_i_normalized, S_T_i_normalized, cashflow_i_to_return, derivative_i_raw.squeeze()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6nPrZqavBB_",
        "outputId": "7f2a2ded-6b8e-44ab-dc6c-55e08bc700ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating and saving new K and S_T scalers to Google Drive...\n",
            "***** Generated K_Scalar and S_T_Scalar and saved into Google drive\n",
            "Portfolio Features:\n",
            "tensor([[ 7.8491e+02,  0.0000e+00,  2.5000e-01],\n",
            "        [ 9.9223e+02,  1.0000e+00,  1.0000e+00],\n",
            "        [ 1.0181e+03,  1.0000e+00, -2.5000e-01]], device='cuda:0')\n",
            "ST\n",
            "tensor([744.2042, 816.3430], device='cuda:0')\n",
            "Cashflow for first sample:\n",
            "tensor([10.1776,  0.0000], device='cuda:0')\n",
            "DErivative first sample:\n",
            "tensor([-0.0064,  0.1364], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "dataset = OperatorDatasetStandarization(num_samples=3, portfolio_size=3, num_samples_S_T=2, is_fitting_mode=True)\n",
        "\n",
        "\n",
        "# Access the first sample in the dataset (index 0)\n",
        "portfolio_features_tensor, S_T_i, cashflow_i, derivative_i = dataset[0]\n",
        "\n",
        "# Print the cashflow\n",
        "print(\"Portfolio Features:\")\n",
        "print(portfolio_features_tensor)\n",
        "\n",
        "print(\"ST\")\n",
        "print(S_T_i)\n",
        "print(\"Cashflow for first sample:\")\n",
        "print(cashflow_i)\n",
        "print(\"DErivative first sample:\")\n",
        "print(derivative_i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qckcoG7g4JrV",
        "outputId": "4544f705-3c41-426e-cbf6-22be100665d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating 100000 samples to fit Cashflow Scaler...\n",
            "Loading K and S_T scalers from Google Drive...\n",
            "Fitting Cashflow Scaler on 100000 samples...\n",
            "Cashflow Scaler fitted and saved to /content/drive/MyDrive/Ucl/Cashflow_scalar.pkl\n",
            "Cashflow Mean: 0.1338, Std Dev: 704.7646\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch.multiprocessing as mp\n",
        "CASHFLOW_SCALAR_FILE = os.path.join(DRIVE_PATH, 'Cashflow_scalar.pkl')\n",
        "\n",
        "def get_raw_cashflow_sample(self, idx):\n",
        "        \"\"\"\n",
        "        Generates and returns only the raw cashflow for a given index.\n",
        "        Useful for fitting the cashflow scaler.\n",
        "        \"\"\"\n",
        "        # Re-using the logic from __getitem__ to generate the necessary components\n",
        "        K, option_types, S_0, weights = generate_option_prices_for_idx(\n",
        "            idx, self.portfolio_size\n",
        "        )\n",
        "        portfolio_features_tensor = torch.stack([\n",
        "            torch.tensor(K, dtype=torch.float32, device=DEVICE),\n",
        "            torch.tensor(option_types, dtype=torch.float32, device=DEVICE),\n",
        "            torch.tensor(weights, dtype=torch.float32, device=DEVICE)\n",
        "        ], dim=-1)\n",
        "        weights_i = torch.tensor(weights, dtype=torch.float32, device=DEVICE)\n",
        "        S_0_i = torch.tensor(S_0, dtype=torch.float32, device=DEVICE)\n",
        "        Z = torch.clamp(torch.randn(self.num_samples_S_T, device=DEVICE), -3, 3)\n",
        "        S_T_i = S_0_i * torch.exp((MU - 0.5 * SIGMA**2) * T + SIGMA * torch.sqrt(torch.tensor(T, device=DEVICE)) * Z)\n",
        "        S_T_i += torch.randn_like(S_T_i, device=DEVICE) * (NOISE_STD * S_T_i)\n",
        "\n",
        "        cashflow_i_raw, _ = compute_cashflow(\n",
        "            portfolio_features_tensor.expand(self.num_samples_S_T, -1, -1),\n",
        "            S_T_i.unsqueeze(-1),\n",
        "            weights_i.expand(self.num_samples_S_T, -1)\n",
        "        )\n",
        "        return cashflow_i_raw.squeeze().cpu().numpy()\n",
        "\n",
        "\n",
        "CASHFLOW_SCALER_FIT_SAMPLES = 100000\n",
        "\n",
        "print(f\"Generating {CASHFLOW_SCALER_FIT_SAMPLES} samples to fit Cashflow Scaler...\")\n",
        "fitting_dataset = OperatorDatasetStandarization(\n",
        "    num_samples=CASHFLOW_SCALER_FIT_SAMPLES,\n",
        "    portfolio_size=200, # Use your desired portfolio_size\n",
        "    num_samples_S_T=1, # Use your desired num_samples_S_T\n",
        "    is_fitting_mode=True # This tells the dataset to return raw cashflows\n",
        ")\n",
        "\n",
        "\n",
        "fitting_loader = DataLoader(fitting_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "all_raw_cashflows_for_fitting = []\n",
        "for i, (_, _, raw_cashflow_batch, _) in enumerate(fitting_loader):\n",
        "    all_raw_cashflows_for_fitting.append(raw_cashflow_batch.view(-1).cpu().numpy()) # Flatten, move to CPU, and convert to numpy\n",
        "\n",
        "\n",
        "# Concatenate all collected cashflows\n",
        "all_raw_cashflows_for_fitting = np.concatenate(all_raw_cashflows_for_fitting).reshape(-1, 1)\n",
        "\n",
        "print(f\"Fitting Cashflow Scaler on {len(all_raw_cashflows_for_fitting)} samples...\")\n",
        "cashflow_scaler = StandardScaler() # StandardScaler is usually good for financial values\n",
        "cashflow_scaler.fit(all_raw_cashflows_for_fitting)\n",
        "\n",
        "# Save the cashflow scaler\n",
        "joblib.dump(cashflow_scaler, CASHFLOW_SCALAR_FILE)\n",
        "print(f\"Cashflow Scaler fitted and saved to {CASHFLOW_SCALAR_FILE}\")\n",
        "print(f\"Cashflow Mean: {cashflow_scaler.mean_[0]:.4f}, Std Dev: {cashflow_scaler.scale_[0]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1is0q7LjQoI-"
      },
      "source": [
        "#Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2vX-i_17JneV"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class AttentionPooling(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(AttentionPooling, self).__init__()\n",
        "        # Define a learnable weight for attention scores (query)\n",
        "        self.attention_weights = nn.Parameter(torch.randn(hidden_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: [batch_size, seq_len, hidden_dim] - sequence of input features\n",
        "        Returns:\n",
        "            pooled: [batch_size, hidden_dim] - attention-based pooled representation\n",
        "        \"\"\"\n",
        "        # Calculate attention scores (dot product between sequence and attention weights)\n",
        "        attention_scores = torch.matmul(x, self.attention_weights)  # [batch_size, seq_len]\n",
        "\n",
        "        # Apply softmax to get the attention weights (normalized)\n",
        "        attention_weights = torch.softmax(attention_scores, dim=1)  # [batch_size, seq_len]\n",
        "\n",
        "        # Apply attention weights to the sequence\n",
        "        weighted_sum = torch.sum(x * attention_weights.unsqueeze(-1), dim=1)  # [batch_size, hidden_dim]\n",
        "\n",
        "        return weighted_sum\n",
        "\n",
        "class MinMaxPooling(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: [batch_size, seq_len, dim]\n",
        "        Returns:\n",
        "            pooled: [batch_size, dim]\n",
        "        \"\"\"\n",
        "        min_pooled, _ = torch.min(x, dim=1)  # [batch_size, dim]\n",
        "        max_pooled, _ = torch.max(x, dim=1)  # [batch_size, dim]\n",
        "        pooled = 0.5 * (min_pooled + max_pooled)\n",
        "        return pooled\n",
        "\n",
        "\n",
        "\n",
        "class InducedSetTransformerEncoder(nn.Module):\n",
        "    \"\"\"Set Transformer with Induced Self-Attention using PyTorch components\"\"\"\n",
        "    def __init__(self, portfolio_feature_dim=3, latent_dim=128, hidden_dim=64,\n",
        "                 num_layers=2, num_heads=4, num_inducing=16, dropout_prob=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        if hidden_dim % num_heads != 0:\n",
        "            hidden_dim = ((hidden_dim // num_heads) + 1) * num_heads\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_inducing = num_inducing\n",
        "\n",
        "        # Input projection\n",
        "        self.input_proj = nn.Sequential(\n",
        "            nn.Linear(portfolio_feature_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_prob * 0.5)\n",
        "        )\n",
        "\n",
        "        # Learnable inducing points (using PyTorch default initialization)\n",
        "        self.inducing_points = nn.Parameter(torch.randn(1, num_inducing, hidden_dim))\n",
        "\n",
        "        # ISAB layers using MultiheadAttention\n",
        "        self.isab_layers = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.isab_layers.append(ISABLayer(hidden_dim, num_heads, dropout_prob))\n",
        "\n",
        "        # Final pooling and projection\n",
        "        self.final_attention = nn.MultiheadAttention(\n",
        "            hidden_dim, num_heads, dropout=dropout_prob, batch_first=True\n",
        "        )\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        self.output_proj = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.Linear(hidden_dim, latent_dim),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # Custom weight initialization removed - using PyTorch defaults\n",
        "\n",
        "    def forward(self, portfolio):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            portfolio: [batch_size, portfolio_size, portfolio_feature_dim]\n",
        "        Returns:\n",
        "            [batch_size, latent_dim]\n",
        "        \"\"\"\n",
        "        batch_size = portfolio.size(0)\n",
        "        x = self.input_proj(portfolio)  # [B, P, H]\n",
        "\n",
        "        # Expand inducing points for batch\n",
        "        inducing = self.inducing_points.expand(batch_size, -1, -1)  # [B, I, H]\n",
        "\n",
        "        # Apply ISAB layers\n",
        "        for isab in self.isab_layers:\n",
        "            x = isab(x, inducing)\n",
        "\n",
        "        # Final attention pooling using inducing points as queries\n",
        "        pooled, _ = self.final_attention(inducing, x, x)  # [B, I, H]\n",
        "\n",
        "        # Global average pooling over inducing points\n",
        "        pooled = pooled.mean(dim=1)  # [B, H]\n",
        "\n",
        "        out = self.output_proj(pooled)  # [B, latent_dim]\n",
        "        return out\n",
        "\n",
        "\n",
        "class ISABLayer(nn.Module):\n",
        "    \"\"\"Induced Self-Attention Block using PyTorch's MultiheadAttention\"\"\"\n",
        "    def __init__(self, hidden_dim, num_heads, dropout_prob=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attn1 = nn.MultiheadAttention(\n",
        "            hidden_dim, num_heads, dropout=dropout_prob, batch_first=True\n",
        "        )\n",
        "        self.attn2 = nn.MultiheadAttention(\n",
        "            hidden_dim, num_heads, dropout=dropout_prob, batch_first=True\n",
        "        )\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
        "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
        "        self.norm3 = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim * FEED_FWD_DEPTH),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_prob),\n",
        "            nn.Linear(hidden_dim * FEED_FWD_DEPTH, hidden_dim)\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, x, inducing_points):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: [batch_size, seq_len, hidden_dim] - input sequence\n",
        "            inducing_points: [batch_size, num_inducing, hidden_dim]\n",
        "        Returns:\n",
        "            [batch_size, seq_len, hidden_dim]\n",
        "        \"\"\"\n",
        "        # Step 1: Inducing points attend to input\n",
        "        h, _ = self.attn1(\n",
        "            self.norm1(inducing_points),  # query\n",
        "            self.norm2(x),                # key\n",
        "            self.norm2(x)                 # value\n",
        "        )  # [B, I, H]\n",
        "\n",
        "        # Step 2: Input attends to processed inducing points\n",
        "        x_out, _ = self.attn2(\n",
        "            self.norm3(x),  # query\n",
        "            h,              # key\n",
        "            h               # value\n",
        "        )  # [B, P, H]\n",
        "\n",
        "        # Residual connection\n",
        "        x = x + self.dropout(x_out)\n",
        "\n",
        "        # Feedforward with residual\n",
        "        x = x + self.dropout(self.ff(self.norm3(x)))\n",
        "\n",
        "        return x\n",
        "\n",
        "class OptimizedTrunkNet(nn.Module):\n",
        "    \"\"\"Trunk Network with increased depth/layers\"\"\"\n",
        "    def __init__(self, input_dim=1, latent_dim=128, hidden_dim=64, dropout_prob=0.1, num_hidden_layers=2):\n",
        "        # ^^^^^ ADDED num_hidden_layers parameter\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_proj = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout_prob)\n",
        "        )\n",
        "\n",
        "        # Dynamically create more hidden layers\n",
        "        layers = []\n",
        "        for _ in range(num_hidden_layers): # This now represents the additional blocks\n",
        "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "            layers.append(nn.GELU())\n",
        "            layers.append(nn.Dropout(dropout_prob))\n",
        "\n",
        "        # Remove the last dropout if it's not desired before the final layer\n",
        "        if layers and isinstance(layers[-1], nn.Dropout):\n",
        "            layers = layers[:-1]\n",
        "\n",
        "        self.ff_block = nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "        self.output_proj = nn.Linear(hidden_dim, latent_dim)\n",
        "\n",
        "    def forward(self, S_T):\n",
        "        batch_size = S_T.shape[0]\n",
        "\n",
        "        if S_T.dim() == 2:\n",
        "            num_samples = S_T.shape[1]\n",
        "            S_T_flat = S_T.reshape(-1, 1)\n",
        "        else:\n",
        "            raise ValueError(f\"Expected shape [B, N], got {S_T.shape}\")\n",
        "\n",
        "        x = self.input_proj(S_T_flat)            # [B * N, H]\n",
        "        x = self.ff_block(x)                     # [B * N, H]\n",
        "        x = self.output_proj(x)                  # [B * N, latent_dim]\n",
        "        x = x.view(batch_size, num_samples, -1)  # [B, N, latent_dim]\n",
        "\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nfvDrm4TPx9x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.amp import autocast, GradScaler\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "\n",
        "FEED_FWD_DEPTH = 2\n",
        "\n",
        "\n",
        "class TrunkNet(nn.Module):\n",
        "    def __init__(self, input_dim=1,  # S_T is scalar\n",
        "                 latent_dim=64,\n",
        "                 hidden_dim=32,\n",
        "                 num_layers=4,\n",
        "                 dropout_prob=0.3):\n",
        "          super(TrunkNet, self).__init__()\n",
        "          layers = []\n",
        "\n",
        "          layers.append(nn.Linear(input_dim, hidden_dim))\n",
        "          layers.append(nn.LayerNorm(hidden_dim))\n",
        "          layers.append(nn.ReLU())\n",
        "          layers.append(nn.Dropout(dropout_prob)) # <--- UNCOMMENT THIS\n",
        "          for _ in range(num_layers - 1):\n",
        "              layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "              layers.append(nn.LayerNorm(hidden_dim))\n",
        "              layers.append(nn.ReLU())\n",
        "              layers.append(nn.Dropout(dropout_prob)) # <--- AND THIS\n",
        "          layers.append(nn.Linear(hidden_dim, latent_dim))\n",
        "          self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, S_T):\n",
        "        if S_T.dim() == 1:\n",
        "          S_T = S_T.unsqueeze(-1)  # (batch_size,) â†’ (batch_size, 1)\n",
        "        elif S_T.dim() == 2:\n",
        "          S_T = S_T.unsqueeze(-1)\n",
        "        result = self.net(S_T)\n",
        "        return result      # [B, N, latent_dim]\n",
        "\n",
        "\n",
        "class OptimizedSetTransformerEncoder(nn.Module):\n",
        "    \"\"\"Set Transformer using PyTorch's built-in TransformerEncoder\"\"\"\n",
        "    def __init__(self, portfolio_feature_dim=3, latent_dim=128, hidden_dim=64,\n",
        "                 num_layers=1, num_heads=2, dropout_prob=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # Ensure hidden_dim is divisible by num_heads\n",
        "        if hidden_dim % num_heads != 0:\n",
        "            hidden_dim = ((hidden_dim // num_heads) + 1) * num_heads\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Input projection\n",
        "        self.input_proj = nn.Sequential(\n",
        "            nn.Linear(portfolio_feature_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.GELU(),  #\n",
        "            nn.Dropout(dropout_prob * 0.5)\n",
        "        )\n",
        "\n",
        "        # PyTorch's built-in TransformerEncoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=hidden_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=hidden_dim * FEED_FWD_DEPTH,\n",
        "            dropout=dropout_prob,\n",
        "            activation='gelu',\n",
        "            batch_first=True,  # Important: input shape is [batch, seq, feature]\n",
        "            norm_first=True    # Pre-norm (more stable)\n",
        "        )\n",
        "\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=num_layers,\n",
        "            enable_nested_tensor=False  # For compatibility\n",
        "        )\n",
        "\n",
        "        # Pooling and output projection\n",
        "        self.min_max_pool = MinMaxPooling(hidden_dim)\n",
        "\n",
        "        self.output_proj = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.Dropout(dropout_prob * 0.5),  # Additional dropout\n",
        "            nn.Linear(hidden_dim, latent_dim)\n",
        "        )\n",
        "\n",
        "        # Custom weight initialization removed - using PyTorch defaults\n",
        "\n",
        "    def forward(self, portfolio):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            portfolio: [batch_size, portfolio_size, portfolio_feature_dim]\n",
        "        Returns:\n",
        "            [batch_size, latent_dim]\n",
        "        \"\"\"\n",
        "        x = self.input_proj(portfolio)  # [B, P, H]\n",
        "\n",
        "        # PyTorch transformer expects [batch, seq, feature] with batch_first=True\n",
        "        x = self.transformer_encoder(x)  # [B, P, H]\n",
        "\n",
        "        # Pool across sequence dimension\n",
        "        x = torch.mean(x, dim=1)   # [B, H]\n",
        "\n",
        "        #x = self.min_max_pool(x)  # [B, H]\n",
        "\n",
        "        # Final projection\n",
        "        out = self.output_proj(x)  # [B, latent_dim]\n",
        "\n",
        "        return out\n",
        "\n",
        "class OptimizedDeepONet(nn.Module):\n",
        "    \"\"\"DeepONet with choice of Set Transformer architectures\"\"\"\n",
        "    def __init__(self, portfolio_feature_dim=3, hidden_dim=64, latent_dim=128,\n",
        "                 dropout_prob=0.1, use_induced=False, num_inducing=16, num_heads=2):\n",
        "        super().__init__()\n",
        "\n",
        "        if hidden_dim % num_heads != 0:\n",
        "          recommended = ((hidden_dim // num_heads) + 1) * num_heads\n",
        "          raise ValueError(\n",
        "              f\"hidden_dim ({hidden_dim}) must be divisible by num_heads ({num_heads}). \"\n",
        "              f\"Try hidden_dim={recommended}\"\n",
        "          )\n",
        "\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        # Choose branch network architecture\n",
        "        if use_induced:\n",
        "            self.branch_net = InducedSetTransformerEncoder(\n",
        "                portfolio_feature_dim=portfolio_feature_dim,\n",
        "                latent_dim=latent_dim,\n",
        "                hidden_dim=hidden_dim,\n",
        "                num_inducing=num_inducing,\n",
        "                dropout_prob=dropout_prob\n",
        "            )\n",
        "        else:\n",
        "            self.branch_net = OptimizedSetTransformerEncoder(\n",
        "                portfolio_feature_dim=portfolio_feature_dim,\n",
        "                latent_dim=latent_dim,\n",
        "                hidden_dim=hidden_dim,\n",
        "                dropout_prob=dropout_prob\n",
        "            )\n",
        "\n",
        "        # Trunk network\n",
        "        self.trunk_net = TrunkNet(\n",
        "            input_dim=1,\n",
        "            latent_dim=latent_dim,\n",
        "            hidden_dim=hidden_dim,\n",
        "            dropout_prob=dropout_prob\n",
        "        )\n",
        "\n",
        "        # DeepONet parameters\n",
        "        self.bias = nn.Parameter(torch.zeros(1))\n",
        "        self.branch_scale = nn.Parameter(torch.ones(1) * 0.8)\n",
        "        self.trunk_scale = nn.Parameter(torch.ones(1) * 0.8)\n",
        "\n",
        "    def forward(self, portfolio, S_T):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            portfolio: [batch_size, portfolio_size, 3] - portfolio features\n",
        "            S_T: [batch_size, num_S_T_samples] - multiple S_T values per portfolio\n",
        "\n",
        "        Returns:\n",
        "            cashflows: [batch_size, num_S_T_samples] - predicted cashflows for each S_T\n",
        "        \"\"\"\n",
        "        # Branch network: encode portfolio\n",
        "        branch_out = self.branch_net(portfolio)  # [batch_size, latent_dim]\n",
        "        branch_out = branch_out * self.branch_scale\n",
        "\n",
        "        # Trunk network: process S_T values\n",
        "        trunk_out = self.trunk_net(S_T)  # [batch_size, num_S_T_samples, latent_dim]\n",
        "        trunk_out = trunk_out * self.trunk_scale\n",
        "\n",
        "        # Compute dot product: branch âŠ— trunk\n",
        "        branch_expanded = branch_out.unsqueeze(1)  # [batch_size, 1, latent_dim]\n",
        "\n",
        "\n",
        "        interaction = (branch_expanded * trunk_out).sum(dim=-1)  # [batch_size, num_S_T_samples]\n",
        "\n",
        "        # Add bias\n",
        "        cashflows = interaction + self.bias\n",
        "        return cashflows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tli_kf0VHuvM"
      },
      "source": [
        "# Trainers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4aqaBMUvHsjq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "# REMOVE these global constants, they will be passed during Trainer initialization\n",
        "# LEARNING_RATE = 5e-6\n",
        "# LAMBDA_DERIV = 0.1\n",
        "\n",
        "# ===== DERIVATIVE RESCALING =====\n",
        "def rescale_derivative_autograd(pred_derivative_from_normalized_input, S_T_scalar_normalizer):\n",
        "    data_range = S_T_scalar_normalizer.data_max_[0] - S_T_scalar_normalizer.data_min_[0]\n",
        "\n",
        "    if data_range < 1e-6:\n",
        "        print(f\"WARNING: S_T data_range is extremely small ({data_range}). Derivative might be unstable.\")\n",
        "        return torch.zeros_like(pred_derivative_from_normalized_input)\n",
        "\n",
        "    # âœ… Multiply to rescale back to original S_T scale\n",
        "    rescaled_derivative = pred_derivative_from_normalized_input * data_range\n",
        "    return rescaled_derivative\n",
        "\n",
        "\n",
        "class ExtendedEarlyStopping:\n",
        "    # ... (no changes needed here) ...\n",
        "    def __init__(self, patience=30, min_delta=0.0005, restore_best_weights=True):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.restore_best_weights = restore_best_weights\n",
        "        self.wait = 0\n",
        "        self.stopped_epoch = 0\n",
        "        self.best = float('inf')\n",
        "        self.best_weights = None\n",
        "\n",
        "    def __call__(self, val_loss, model=None):\n",
        "        if val_loss < self.best - self.min_delta:\n",
        "            self.best = val_loss\n",
        "            self.wait = 0\n",
        "            if model is not None and self.restore_best_weights:\n",
        "                self.best_weights = model.state_dict().copy()\n",
        "        else:\n",
        "            self.wait += 1\n",
        "\n",
        "        if self.wait >= self.patience:\n",
        "            self.stopped_epoch = True\n",
        "            if model is not None and self.restore_best_weights and self.best_weights is not None:\n",
        "                model.load_state_dict(self.best_weights)\n",
        "\n",
        "        return self.stopped_epoch\n",
        "\n",
        "class OptimizedTrainer:\n",
        "    def __init__(self, model, device='cuda', monitor_gradients=True,\n",
        "                 scale_warmup_epochs=5, initial_scale=0.05, final_scale=1.0,\n",
        "                 learning_rate=5e-6, lambda_deriv_weight=0.01, weight_decay=1e-4): # ADDED: learning_rate, lambda_deriv_weight, weight_decay for consistency\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "        self.monitor_gradients = monitor_gradients\n",
        "        self.lambda_deriv_weight = lambda_deriv_weight # Store this for compute_loss\n",
        "\n",
        "        self.optimizer = optim.AdamW(\n",
        "            model.parameters(),\n",
        "            lr=learning_rate, # Use the passed learning_rate\n",
        "            weight_decay=weight_decay, # Use the passed weight_decay (or make it a constant here if not configurable)\n",
        "            betas=(0.9, 0.999),\n",
        "            eps=1e-8\n",
        "        )\n",
        "\n",
        "        self.scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "            self.optimizer, T_0=100, T_mult=2, eta_min=1e-6 # T_0 might also be a hyperparameter\n",
        "        )\n",
        "\n",
        "        self.scaler = GradScaler()\n",
        "        self.S_T_scalar = joblib.load(ST_SCALAR_FILE)\n",
        "\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "        self.huber_loss = nn.SmoothL1Loss(beta=1.0)\n",
        "\n",
        "        # Scale warmup parameters\n",
        "        self.scale_warmup_epochs = scale_warmup_epochs\n",
        "        self.initial_scale = initial_scale\n",
        "        self.final_scale = final_scale\n",
        "\n",
        "        # Initialize model scales\n",
        "        if hasattr(self.model, 'branch_scale') and hasattr(self.model, 'trunk_scale'):\n",
        "            with torch.no_grad():\n",
        "                self.model.branch_scale.fill_(initial_scale)\n",
        "                self.model.trunk_scale.fill_(initial_scale)\n",
        "\n",
        "    def check_model_health(self, epoch, batch_idx):\n",
        "        \"\"\"Check model parameters for NaN/Inf values\"\"\"\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if torch.isnan(param).any():\n",
        "                print(f\"ðŸš¨ NaN parameter found: {name} at Epoch {epoch}, Batch {batch_idx}\")\n",
        "                return False\n",
        "            if torch.isinf(param).any():\n",
        "                print(f\"ðŸš¨ Inf parameter found: {name} at Epoch {epoch}, Batch {batch_idx}\")\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def compute_loss(self, pred_cashflow, true_cashflow, pred_deriv, true_deriv,\n",
        "                     lambda_reg=1e-4): # REMOVED lambda_deriv parameter, use self.lambda_deriv_weight\n",
        "        cashflow_loss = self.huber_loss(pred_cashflow, true_cashflow)\n",
        "\n",
        "        if true_deriv is not None:\n",
        "            pred_deriv_rescaled = rescale_derivative_autograd(pred_deriv, self.S_T_scalar)\n",
        "            deriv_loss = self.huber_loss(pred_deriv_rescaled, true_deriv)\n",
        "            total_loss  =  cashflow_loss + self.lambda_deriv_weight * deriv_loss # Use the stored weight\n",
        "        else:\n",
        "             deriv_loss = torch.tensor(0.0, device=pred_cashflow.device)\n",
        "\n",
        "        # l2_reg = sum(p.pow(2).sum() for p in self.model.parameters())\n",
        "        # total_loss += lambda_reg * l2_reg\n",
        "\n",
        "        return total_loss, cashflow_loss, deriv_loss\n",
        "\n",
        "\n",
        "\n",
        "    def train_step(self, portfolio, S_T, cashflow, true_derivative,\n",
        "                  epoch=0, batch_idx=0, experiment=None):\n",
        "\n",
        "        # Check model health before training step\n",
        "        if not self.check_model_health(epoch, batch_idx):\n",
        "            return float('inf'), float('inf'), float('inf')\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # Enable gradients for S_T\n",
        "        S_T = S_T.clone().detach().requires_grad_(True)\n",
        "\n",
        "        try:\n",
        "            #with autocast(device_type=self.device.type):\n",
        "            pred_cashflow = self.model(portfolio, S_T)\n",
        "\n",
        "            # Check prediction health\n",
        "            if torch.isnan(pred_cashflow).any() or torch.isinf(pred_cashflow).any():\n",
        "                print(f\"ðŸš¨ Invalid predictions at Epoch {epoch}, Batch {batch_idx}\")\n",
        "                return float('inf'), float('inf'), float('inf')\n",
        "\n",
        "            # Compute derivatives with error handling\n",
        "            pred_deriv_from_autograd = None\n",
        "            if true_derivative is not None:\n",
        "                try:\n",
        "                    pred_deriv_from_autograd = torch.autograd.grad(\n",
        "                        outputs=pred_cashflow.sum(),  # Sum to get scalar output\n",
        "                        inputs=S_T,\n",
        "                        retain_graph=True,\n",
        "                        create_graph=True,\n",
        "                        allow_unused=True\n",
        "                    )[0]\n",
        "\n",
        "                    # Check derivative health\n",
        "                    if pred_deriv_from_autograd is not None:\n",
        "                        if torch.isnan(pred_deriv_from_autograd).any() or torch.isinf(pred_deriv_from_autograd).any():\n",
        "                            print(f\"ðŸš¨ Invalid derivatives at Epoch {epoch}, Batch {batch_idx}\")\n",
        "                            pred_deriv_from_autograd = None\n",
        "\n",
        "                except RuntimeError as e:\n",
        "                    print(f\"âš ï¸ Derivative computation failed: {e}\")\n",
        "                    pred_deriv_from_autograd = None\n",
        "\n",
        "            total_loss, cashflow_loss, deriv_loss = self.compute_loss(\n",
        "                pred_cashflow, cashflow, pred_deriv_from_autograd, true_derivative\n",
        "            )\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            print(f\"âš ï¸ Forward pass failed at Epoch {epoch}, Batch {batch_idx}: {e}\")\n",
        "            return float('inf'), float('inf'), float('inf')\n",
        "\n",
        "        # Check loss health\n",
        "        if torch.isnan(total_loss) or torch.isinf(total_loss):\n",
        "            print(f\"âš ï¸ Invalid total loss at Epoch {epoch}, Batch {batch_idx}\")\n",
        "            return float('inf'), float('inf'), float('inf')\n",
        "\n",
        "        # Scale and backward pass\n",
        "        scaled_loss = self.scaler.scale(total_loss)\n",
        "        scaled_loss.backward()\n",
        "\n",
        "        # Unscale gradients for inspection\n",
        "        self.scaler.unscale_(self.optimizer)\n",
        "\n",
        "        # Check gradients for NaN/Inf\n",
        "        gradient_health = True\n",
        "        max_grad_norm = 0.0\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.grad is not None:\n",
        "                grad_norm = param.grad.norm().item()\n",
        "                max_grad_norm = max(max_grad_norm, grad_norm)\n",
        "\n",
        "                if torch.isnan(param.grad).any():\n",
        "                    print(f\"ðŸš¨ NaN gradient found: {name} at Epoch {epoch}, Batch {batch_idx}\")\n",
        "                    gradient_health = False\n",
        "                if torch.isinf(param.grad).any():\n",
        "                    print(f\"ðŸš¨ Inf gradient found: {name} at Epoch {epoch}, Batch {batch_idx}\")\n",
        "                    gradient_health = False\n",
        "\n",
        "        if not gradient_health or max_grad_norm > 50.0:\n",
        "            print(f\"ðŸ›‘ Unhealthy gradients detected. Max norm: {max_grad_norm:.4f}\")\n",
        "            self.scaler.update()  # Update scaler even on failure\n",
        "            return float('inf'), float('inf'), float('inf')\n",
        "\n",
        "        # Gradient clipping with more conservative threshold\n",
        "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1)\n",
        "\n",
        "        # Gradient monitoring\n",
        "        if self.monitor_gradients and (batch_idx % 500 == 0 or max_grad_norm > 1.0):\n",
        "            total_norm, gradient_stats, param_count = compute_gradient_stats(self.model)\n",
        "            print_gradient_summary(gradient_stats, total_norm, epoch, batch_idx)\n",
        "\n",
        "        # Optimizer step\n",
        "        self.scaler.step(self.optimizer)\n",
        "        self.scaler.update()\n",
        "        self.scheduler.step()\n",
        "\n",
        "        return total_loss.item(), cashflow_loss.item(), deriv_loss.item()\n",
        "\n",
        "\n",
        "    def val_step(self, portfolio, S_T, cashflow, derivative): # derivative is the true derivative\n",
        "        self.model.eval()\n",
        "\n",
        "        # Ensure S_T requires gradients for derivative calculation in validation\n",
        "        S_T.requires_grad_(True) # Temporarily enable for this specific calculation\n",
        "\n",
        "        with torch.no_grad(): # Outer no_grad block for validation\n",
        "            # Use torch.enable_grad() only around the autograd.grad call if necessary\n",
        "            # For validation, we don't need to retain graph or create graph.\n",
        "            # The model forward is within no_grad, so its parameters won't get gradients.\n",
        "            # Only S_T will have its gradient computed.\n",
        "            with torch.enable_grad(): # Re-enable graph building for derivative computation\n",
        "                pred_cashflow = self.model(portfolio, S_T)\n",
        "                pred_deriv_from_autograd = torch.autograd.grad(\n",
        "                    outputs=pred_cashflow,\n",
        "                    inputs=S_T,\n",
        "                    grad_outputs=torch.ones_like(pred_cashflow),\n",
        "                    retain_graph=False, # No need to retain graph in val\n",
        "                    create_graph=False  # No need for higher-order in val\n",
        "                )[0]\n",
        "\n",
        "            val_total_loss, val_cashflow_loss, val_deriv_loss = self.compute_loss(\n",
        "                pred_cashflow, cashflow, pred_deriv_from_autograd, derivative\n",
        "            )\n",
        "\n",
        "        # Reset requires_grad for S_T after use\n",
        "        if S_T.requires_grad:\n",
        "            S_T.requires_grad_(False)\n",
        "\n",
        "        return val_total_loss.item(), val_cashflow_loss.item(), val_deriv_loss.item()\n",
        "\n",
        "\n",
        "    def update_scale(self, current_epoch):\n",
        "        # ... (no changes needed here) ...\n",
        "        if hasattr(self.model, 'branch_scale') and hasattr(self.model, 'trunk_scale'):\n",
        "            # Linear warmup from initial_scale to final_scale over scale_warmup_epochs\n",
        "            if current_epoch < self.scale_warmup_epochs:\n",
        "                factor = (current_epoch + 1) / self.scale_warmup_epochs\n",
        "                new_scale = self.initial_scale + (self.final_scale - self.initial_scale) * factor\n",
        "            else:\n",
        "                new_scale = self.final_scale\n",
        "\n",
        "            with torch.no_grad():\n",
        "                self.model.branch_scale.fill_(new_scale)\n",
        "                self.model.trunk_scale.fill_(new_scale)\n",
        "\n",
        "            print(f\"ðŸ”§ [Epoch {current_epoch}] Updated branch/trunk scale â†’ {new_scale:.4f}\")\n",
        "\n",
        "# ... (compute_gradient_stats, print_gradient_summary, get_stable_hyperparameters remain the same) ...\n",
        "# Ensure get_stable_hyperparameters defines learning_rate and lambda_deriv as it will be used directly.\n",
        "def get_stable_hyperparameters():\n",
        "    \"\"\"Return more stable hyperparameters\"\"\"\n",
        "    return {\n",
        "        \"learning_rate\": 1e-5,\n",
        "        \"weight_decay\": 5e-4,\n",
        "        \"lambda_deriv\": 0.1,\n",
        "        \"lambda_reg\": 1e-4,\n",
        "        \"gradient_clip_norm\": 1,\n",
        "        \"batch_size\": 32,\n",
        "        \"scheduler_T0\": 200,\n",
        "        \"early_stopping_patience\": 50,\n",
        "    }\n",
        "\n",
        "\n",
        "def compute_gradient_stats(model):\n",
        "    \"\"\"Compute gradient statistics - fixed for single-element tensors\"\"\"\n",
        "    total_norm = 0\n",
        "    param_count = 0\n",
        "    gradient_stats = {}\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.grad is not None:\n",
        "            param_norm = param.grad.data.norm(2)\n",
        "            total_norm += param_norm.item() ** 2\n",
        "            param_count += 1\n",
        "\n",
        "            grad_data = param.grad.data\n",
        "            if grad_data.numel() > 1:\n",
        "                grad_std = grad_data.std(unbiased=False).item()\n",
        "            else:\n",
        "                grad_std = 0.0 # Handle single-element tensors\n",
        "\n",
        "            gradient_stats[name] = {\n",
        "                'norm': param_norm.item(),\n",
        "                'mean': grad_data.mean().item(),\n",
        "                'std': grad_std,\n",
        "                'max': grad_data.max().item(),\n",
        "                'min': grad_data.min().item(),\n",
        "                'shape': list(param.grad.shape),\n",
        "                'numel': grad_data.numel()\n",
        "            }\n",
        "\n",
        "    total_norm = total_norm ** (1. / 2)\n",
        "    return total_norm, gradient_stats, param_count\n",
        "\n",
        "def print_gradient_summary(gradient_stats, total_norm, epoch, batch_idx=None):\n",
        "    \"\"\"Enhanced gradient summary with more details\"\"\"\n",
        "    prefix = f\"Epoch {epoch}\" + (f\", Batch {batch_idx}\" if batch_idx is not None else \"\")\n",
        "    print(f\"\\nðŸ” === Gradient Analysis - {prefix} ===\")\n",
        "    print(f\"Total Gradient Norm: {total_norm:.6f}\")\n",
        "\n",
        "    if total_norm > 20.0:\n",
        "        print(\"ðŸš¨ CRITICAL: Severe gradient explosion! Consider stopping training.\")\n",
        "    elif total_norm > 10.0:\n",
        "        print(\"âš ï¸  SEVERE: Major gradient explosion detected!\")\n",
        "    elif total_norm > 5.0:\n",
        "        print(\"âš ï¸  WARNING: Moderate gradient explosion detected!\")\n",
        "    elif total_norm < 1e-6:\n",
        "        print(\"âš ï¸  WARNING: Vanishing gradients detected!\")\n",
        "    else:\n",
        "        print(\"âœ… Gradient norm is healthy\")\n",
        "\n",
        "    sorted_layers = sorted(gradient_stats.items(), key=lambda x: x[1]['norm'], reverse=True)\n",
        "    print(f\"\\nTop 5 layers by gradient norm (out of {len(gradient_stats)} total):\")\n",
        "    for i, (layer_name, stats) in enumerate(sorted_layers[:5]):\n",
        "        status = \"ðŸ”¥\" if stats['norm'] > 3.0 else \"âš ï¸\" if stats['norm'] > 1.0 else \"âœ…\"\n",
        "        print(f\"  {status} {i+1}. {layer_name}: {stats['norm']:.4f}\")\n",
        "        print(f\"      Shape: {stats['shape']}, Elements: {stats['numel']}\")\n",
        "        print(f\"      Mean: {stats['mean']:.6f}, Std: {stats['std']:.6f}\")\n",
        "\n",
        "    print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OiiWvGDQydJ"
      },
      "source": [
        "# Start Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "-vGHXVVrNNTG",
        "outputId": "d3435567-088e-4ad2-f628-0a574e8167d1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'experiment' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-15-951053477.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'experiment' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "experiment.end()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESQzbNfEgdBg",
        "outputId": "68c45cec-409f-4ec6-87ad-8cd7627c3966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Epoch 29:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 599/1280 [01:27<01:39,  6.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 597 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5943\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000003, Std: 0.010723\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4820\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000006, Std: 0.015062\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3200\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000005, Std: 0.010001\n",
            "  âœ… 4. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2539\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000008, Std: 0.005610\n",
            "  âœ… 5. trunk_net.net.16.weight: 0.2350\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000413, Std: 0.007332\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 598 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.6007\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000002, Std: 0.010838\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4856\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000010, Std: 0.015175\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.2351\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000034, Std: 0.007348\n",
            "  âœ… 4. branch_net.input_proj.0.weight: 0.2345\n",
            "      Shape: [32, 3], Elements: 96\n",
            "      Mean: -0.000000, Std: 0.023930\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2296\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000003, Std: 0.005074\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 601/1280 [01:27<01:37,  7.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 599 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5923\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000003, Std: 0.010686\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4527\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000002, Std: 0.014148\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3440\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000025, Std: 0.010749\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2760\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000194, Std: 0.008622\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2259\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000013, Std: 0.004991\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 603/1280 [01:27<01:37,  6.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 601 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5166\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000002, Std: 0.009321\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4475\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000060, Std: 0.013984\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3756\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000068, Std: 0.011738\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.3024\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.001340, Std: 0.009356\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2629\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000049, Std: 0.005809\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 602 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5931\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000002, Std: 0.010701\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4532\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000014, Std: 0.014164\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3454\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000024, Std: 0.010794\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2762\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000473, Std: 0.008618\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2248\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000002, Std: 0.004967\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 605/1280 [01:28<01:37,  6.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 603 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5699\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000002, Std: 0.010283\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4451\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000013, Std: 0.013911\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3221\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000030, Std: 0.010064\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2589\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.001020, Std: 0.008027\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2375\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000018, Std: 0.005249\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 604 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5349\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000002, Std: 0.009651\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4795\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000044, Std: 0.014984\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3800\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000018, Std: 0.011874\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2736\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000593, Std: 0.008530\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2702\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000011, Std: 0.005971\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 607/1280 [01:28<01:38,  6.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 605 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5932\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000003, Std: 0.010703\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4521\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000002, Std: 0.014129\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3430\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000032, Std: 0.010720\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2622\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000194, Std: 0.008192\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2426\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000011, Std: 0.005361\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 606 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5686\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000003, Std: 0.010258\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4456\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000012, Std: 0.013926\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3878\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000023, Std: 0.012120\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.3052\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000164, Std: 0.009536\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2533\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000003, Std: 0.005598\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 610/1280 [01:29<01:40,  6.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 608 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5723\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000003, Std: 0.010325\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4573\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000025, Std: 0.014291\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3768\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000016, Std: 0.011775\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2872\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000222, Std: 0.008973\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2396\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000000, Std: 0.005295\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 609 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5913\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000003, Std: 0.010668\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4511\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000005, Std: 0.014097\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3474\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000068, Std: 0.010856\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2799\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000503, Std: 0.008732\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2428\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000015, Std: 0.005365\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 613/1280 [01:29<01:35,  6.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 611 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5718\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000003, Std: 0.010317\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4661\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000013, Std: 0.014567\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3651\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000010, Std: 0.011409\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2752\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000064, Std: 0.008599\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2549\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000015, Std: 0.005632\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 612 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5864\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000003, Std: 0.010580\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4563\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000012, Std: 0.014260\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.2854\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000025, Std: 0.008920\n",
            "  âœ… 4. branch_net.transformer_encoder.layers.0.linear1.weight: 0.2420\n",
            "      Shape: [64, 32], Elements: 2048\n",
            "      Mean: -0.000003, Std: 0.005347\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2409\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000004, Std: 0.005324\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 615/1280 [01:29<01:36,  6.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 613 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4972\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000025, Std: 0.015536\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.4926\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000001, Std: 0.008887\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3779\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000084, Std: 0.011809\n",
            "  âœ… 4. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2804\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000025, Std: 0.006196\n",
            "  âœ… 5. trunk_net.net.16.weight: 0.2713\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000966, Std: 0.008422\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 614 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5677\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000003, Std: 0.010243\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4458\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000007, Std: 0.013930\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3962\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000015, Std: 0.012383\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2977\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000052, Std: 0.009304\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2508\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000002, Std: 0.005542\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 617/1280 [01:30<01:35,  6.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 615 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5104\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000001, Std: 0.009209\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4416\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000005, Std: 0.013801\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3982\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000012, Std: 0.012445\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2891\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.001477, Std: 0.008913\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2550\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000011, Std: 0.005636\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 616 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5677\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000003, Std: 0.010243\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4487\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000016, Std: 0.014023\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3586\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000039, Std: 0.011207\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2817\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000177, Std: 0.008801\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2523\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000004, Std: 0.005575\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 620/1280 [01:30<01:34,  6.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 618 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.5095\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000006, Std: 0.015921\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5020\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000000, Std: 0.009057\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.2743\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000031, Std: 0.008573\n",
            "  âœ… 4. branch_net.input_proj.0.bias: 0.2722\n",
            "      Shape: [32], Elements: 32\n",
            "      Mean: 0.000000, Std: 0.048119\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2674\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000004, Std: 0.005909\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 619 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5182\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000000, Std: 0.009350\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4754\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000013, Std: 0.014855\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3479\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000053, Std: 0.010873\n",
            "  âœ… 4. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2677\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000006, Std: 0.005916\n",
            "  âœ… 5. trunk_net.net.16.weight: 0.2478\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.001007, Std: 0.007677\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 622/1280 [01:30<01:37,  6.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 620 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4976\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000009, Std: 0.015549\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.4965\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000002, Std: 0.008958\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3736\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000081, Std: 0.011674\n",
            "  âœ… 4. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2762\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000019, Std: 0.006102\n",
            "  âœ… 5. trunk_net.net.16.weight: 0.2629\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000797, Std: 0.008178\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 621 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5342\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000001, Std: 0.009637\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.5010\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000043, Std: 0.015657\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.2546\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000009, Std: 0.007955\n",
            "  âœ… 4. branch_net.input_proj.0.weight: 0.2529\n",
            "      Shape: [32, 3], Elements: 96\n",
            "      Mean: 0.000000, Std: 0.025808\n",
            "  âœ… 5. branch_net.input_proj.0.bias: 0.2517\n",
            "      Shape: [32], Elements: 32\n",
            "      Mean: -0.000000, Std: 0.044491\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 624/1280 [01:31<01:36,  6.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 622 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4751\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000011, Std: 0.014847\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.4685\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000000, Std: 0.008452\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3747\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000007, Std: 0.011709\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2694\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.001347, Std: 0.008309\n",
            "  âœ… 5. branch_net.input_proj.0.bias: 0.2606\n",
            "      Shape: [32], Elements: 32\n",
            "      Mean: 0.000000, Std: 0.046077\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 623 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5466\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000001, Std: 0.009861\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4630\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000038, Std: 0.014469\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3441\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000008, Std: 0.010752\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2805\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000835, Std: 0.008727\n",
            "  âœ… 5. branch_net.input_proj.0.weight: 0.2246\n",
            "      Shape: [32, 3], Elements: 96\n",
            "      Mean: -0.000000, Std: 0.022928\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 626/1280 [01:31<01:36,  6.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 624 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5391\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000002, Std: 0.009727\n",
            "  âœ… 2. branch_net.output_proj.2.weight: 0.4236\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000020, Std: 0.013236\n",
            "  âœ… 3. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4133\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000004, Std: 0.012915\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.3317\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000905, Std: 0.010327\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2431\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000007, Std: 0.005371\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 628/1280 [01:31<01:34,  6.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 626 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5029\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000001, Std: 0.009074\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.5015\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000027, Std: 0.015673\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3643\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000082, Std: 0.011383\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2743\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000548, Std: 0.008555\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2624\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000002, Std: 0.005798\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 627 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5668\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000000, Std: 0.010227\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4771\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000077, Std: 0.014910\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3140\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000018, Std: 0.009814\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2606\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000219, Std: 0.008140\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2397\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000035, Std: 0.005298\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 630/1280 [01:31<01:33,  6.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 628 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5586\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000002, Std: 0.010078\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4663\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000023, Std: 0.014571\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3631\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000060, Std: 0.011347\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2835\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000852, Std: 0.008820\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2610\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000029, Std: 0.005767\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 632/1280 [01:32<01:32,  7.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 630 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5504\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000003, Std: 0.009931\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4634\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000004, Std: 0.014482\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3949\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000002, Std: 0.012339\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.3023\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000336, Std: 0.009441\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2367\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000014, Std: 0.005230\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 631 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5924\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000004, Std: 0.010689\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4566\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000022, Std: 0.014268\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3127\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000010, Std: 0.009771\n",
            "  âœ… 4. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2700\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000007, Std: 0.005966\n",
            "  âœ… 5. trunk_net.net.16.weight: 0.2320\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000182, Std: 0.007248\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 635/1280 [01:32<01:34,  6.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 633 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5177\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000002, Std: 0.009341\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4747\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000026, Std: 0.014834\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3799\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000015, Std: 0.011871\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.3017\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000080, Std: 0.009429\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2685\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000025, Std: 0.005933\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 634 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5178\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000002, Std: 0.009343\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4437\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000001, Std: 0.013865\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.4338\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000032, Std: 0.013558\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.3169\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000663, Std: 0.009881\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2699\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000006, Std: 0.005964\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 637/1280 [01:32<01:33,  6.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 635 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5161\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000002, Std: 0.009312\n",
            "  âœ… 2. branch_net.output_proj.2.weight: 0.4877\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000039, Std: 0.015240\n",
            "  âœ… 3. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.3946\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000011, Std: 0.012331\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.3520\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000014, Std: 0.011001\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2639\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000001, Std: 0.005832\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 636 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.6032\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000004, Std: 0.010883\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4623\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000006, Std: 0.014447\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.2901\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000002, Std: 0.009065\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2431\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000389, Std: 0.007586\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2419\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000004, Std: 0.005345\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 639/1280 [01:33<01:33,  6.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 637 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5898\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000003, Std: 0.010641\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4657\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000017, Std: 0.014552\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3385\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000030, Std: 0.010578\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2765\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000060, Std: 0.008639\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2365\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000002, Std: 0.005225\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 638 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5608\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000003, Std: 0.010118\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4995\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000006, Std: 0.015611\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3360\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000003, Std: 0.010501\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2594\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000571, Std: 0.008085\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2516\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000019, Std: 0.005560\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 641/1280 [01:33<01:30,  7.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 639 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.6071\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000003, Std: 0.010953\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4744\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000008, Std: 0.014825\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.2905\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000023, Std: 0.009077\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2371\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000120, Std: 0.007408\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2359\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000011, Std: 0.005214\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 640 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.4892\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000002, Std: 0.008827\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4527\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000014, Std: 0.014148\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3701\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000057, Std: 0.011566\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.3025\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000750, Std: 0.009422\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2371\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000010, Std: 0.005240\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 643/1280 [01:33<01:31,  6.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 641 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5484\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000003, Std: 0.009895\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4639\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000038, Std: 0.014497\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3780\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000000, Std: 0.011814\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2981\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000166, Std: 0.009313\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2485\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000009, Std: 0.005491\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 642 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5714\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000002, Std: 0.010310\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4629\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000026, Std: 0.014467\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3324\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000038, Std: 0.010388\n",
            "  âœ… 4. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2646\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000006, Std: 0.005847\n",
            "  âœ… 5. trunk_net.net.16.weight: 0.2588\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000424, Std: 0.008078\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 646/1280 [01:34<01:32,  6.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 644 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5725\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000002, Std: 0.010329\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4563\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000004, Std: 0.014258\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3331\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000003, Std: 0.010409\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2662\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000611, Std: 0.008297\n",
            "  âœ… 5. branch_net.input_proj.0.bias: 0.2218\n",
            "      Shape: [32], Elements: 32\n",
            "      Mean: -0.000000, Std: 0.039209\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 645 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5528\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000003, Std: 0.009973\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4287\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000009, Std: 0.013395\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.4058\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000009, Std: 0.012681\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.3068\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000319, Std: 0.009581\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2601\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000009, Std: 0.005747\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 648/1280 [01:34<01:30,  6.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 646 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5890\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000003, Std: 0.010627\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4721\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000011, Std: 0.014754\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3292\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000015, Std: 0.010289\n",
            "  âœ… 4. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2516\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000010, Std: 0.005560\n",
            "  âœ… 5. trunk_net.net.16.weight: 0.2444\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000239, Std: 0.007634\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 651/1280 [01:34<01:29,  7.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 649 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4804\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000042, Std: 0.015014\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.4644\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000001, Std: 0.008379\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3873\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000091, Std: 0.012103\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2743\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.001241, Std: 0.008481\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2607\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000013, Std: 0.005762\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 650 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5427\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000003, Std: 0.009791\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4522\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000006, Std: 0.014132\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.4183\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000052, Std: 0.013073\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2990\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000270, Std: 0.009338\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2409\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000035, Std: 0.005324\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 655/1280 [01:35<01:27,  7.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 653 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5623\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000001, Std: 0.010144\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4693\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000003, Std: 0.014666\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3044\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000013, Std: 0.009512\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2468\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000891, Std: 0.007660\n",
            "  âœ… 5. branch_net.input_proj.0.bias: 0.2417\n",
            "      Shape: [32], Elements: 32\n",
            "      Mean: -0.000000, Std: 0.042736\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 654 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5378\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000002, Std: 0.009703\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4636\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000026, Std: 0.014488\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.4004\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000005, Std: 0.012514\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.3120\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000462, Std: 0.009740\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2598\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000007, Std: 0.005741\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 657/1280 [01:35<01:28,  7.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 655 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.4938\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000002, Std: 0.008910\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4855\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000001, Std: 0.015173\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3986\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000046, Std: 0.012456\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2781\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000825, Std: 0.008651\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2576\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000001, Std: 0.005693\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 656 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5715\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000002, Std: 0.010311\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4424\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000004, Std: 0.013824\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3603\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000065, Std: 0.011260\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2908\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000339, Std: 0.009081\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2275\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000005, Std: 0.005026\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 659/1280 [01:36<01:28,  7.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 657 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5341\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000002, Std: 0.009636\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4358\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000005, Std: 0.013618\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.4259\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000031, Std: 0.013308\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.3300\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000313, Std: 0.010307\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2643\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000040, Std: 0.005840\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 658 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5032\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000000, Std: 0.009078\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4905\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000015, Std: 0.015328\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3397\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000084, Std: 0.010614\n",
            "  âœ… 4. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2571\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000002, Std: 0.005682\n",
            "  âœ… 5. trunk_net.net.16.weight: 0.2522\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000946, Std: 0.007824\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 661/1280 [01:36<01:31,  6.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 659 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5160\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000002, Std: 0.009310\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4861\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000051, Std: 0.015191\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3549\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000010, Std: 0.011092\n",
            "  âœ… 4. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2733\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000018, Std: 0.006039\n",
            "  âœ… 5. trunk_net.net.16.weight: 0.2582\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000561, Std: 0.008048\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 660 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.4813\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000002, Std: 0.008684\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4773\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000010, Std: 0.014915\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.4270\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000035, Std: 0.013344\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2996\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.001120, Std: 0.009294\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2594\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000009, Std: 0.005733\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 663/1280 [01:36<01:29,  6.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 661 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5912\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000002, Std: 0.010667\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4593\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000010, Std: 0.014352\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3284\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000001, Std: 0.010261\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2749\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000228, Std: 0.008587\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2194\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000000, Std: 0.004849\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 662 ===\n",
            "Total Gradient Norm: 0.999999\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5725\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000003, Std: 0.010329\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4879\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000028, Std: 0.015248\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3145\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000031, Std: 0.009828\n",
            "  âœ… 4. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2897\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000042, Std: 0.006402\n",
            "  âœ… 5. trunk_net.net.16.weight: 0.2477\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000414, Std: 0.007729\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 665/1280 [01:36<01:27,  7.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 663 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5491\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000002, Std: 0.009907\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4825\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000005, Std: 0.015077\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3806\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000046, Std: 0.011893\n",
            "  âœ… 4. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2805\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000005, Std: 0.006199\n",
            "  âœ… 5. trunk_net.net.16.weight: 0.2656\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000364, Std: 0.008292\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 667/1280 [01:37<01:31,  6.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 665 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4963\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000029, Std: 0.015508\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.4943\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000002, Std: 0.008919\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3834\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000012, Std: 0.011982\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2745\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000619, Std: 0.008556\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2646\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000030, Std: 0.005848\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 666 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5327\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000001, Std: 0.009611\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4780\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000046, Std: 0.014938\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3314\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000087, Std: 0.010357\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2420\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.001067, Std: 0.007488\n",
            "  âœ… 5. branch_net.input_proj.0.bias: 0.2407\n",
            "      Shape: [32], Elements: 32\n",
            "      Mean: -0.000000, Std: 0.042556\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 669/1280 [01:37<01:29,  6.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 667 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5326\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000002, Std: 0.009609\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4865\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000029, Std: 0.015205\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3623\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000011, Std: 0.011322\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2561\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000845, Std: 0.007959\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2503\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000015, Std: 0.005532\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 668 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5494\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000002, Std: 0.009912\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4953\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000048, Std: 0.015479\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3200\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000036, Std: 0.009999\n",
            "  âœ… 4. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2609\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000001, Std: 0.005765\n",
            "  âœ… 5. trunk_net.net.16.weight: 0.2313\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000807, Std: 0.007184\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 672/1280 [01:37<01:29,  6.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 670 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.6188\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000003, Std: 0.011164\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4849\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000040, Std: 0.015154\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.2473\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000022, Std: 0.007727\n",
            "  âœ… 4. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2355\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000008, Std: 0.005204\n",
            "  âœ… 5. trunk_net.net.16.weight: 0.2248\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000554, Std: 0.007004\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 671 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5175\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000002, Std: 0.009337\n",
            "  âœ… 2. branch_net.output_proj.2.weight: 0.4291\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000057, Std: 0.013411\n",
            "  âœ… 3. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4079\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000048, Std: 0.012747\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.3419\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000115, Std: 0.010683\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2554\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000026, Std: 0.005645\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 674/1280 [01:38<01:28,  6.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 672 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5661\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000003, Std: 0.010214\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4610\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000014, Std: 0.014406\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3799\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000021, Std: 0.011873\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2818\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000448, Std: 0.008793\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2486\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000003, Std: 0.005494\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 673 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5711\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000003, Std: 0.010304\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4936\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000017, Std: 0.015424\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3271\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000025, Std: 0.010222\n",
            "  âœ… 4. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2553\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000003, Std: 0.005642\n",
            "  âœ… 5. trunk_net.net.16.weight: 0.2454\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000409, Std: 0.007658\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 676/1280 [01:38<01:27,  6.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 674 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5981\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000002, Std: 0.010791\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4653\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000021, Std: 0.014540\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3091\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000049, Std: 0.009659\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2698\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000267, Std: 0.008428\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2179\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000015, Std: 0.004816\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 675 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5655\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000002, Std: 0.010203\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4605\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000012, Std: 0.014391\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3819\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000035, Std: 0.011935\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2861\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000146, Std: 0.008939\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2582\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000007, Std: 0.005705\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 678/1280 [01:38<01:28,  6.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 676 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5612\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000002, Std: 0.010126\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4586\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000031, Std: 0.014331\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3356\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000047, Std: 0.010487\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2709\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000480, Std: 0.008452\n",
            "  âœ… 5. branch_net.input_proj.0.weight: 0.2277\n",
            "      Shape: [32, 3], Elements: 96\n",
            "      Mean: -0.000000, Std: 0.023243\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 677 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.4958\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000002, Std: 0.008944\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4902\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000021, Std: 0.015320\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3140\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000056, Std: 0.009812\n",
            "  âœ… 4. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2638\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000014, Std: 0.005829\n",
            "  âœ… 5. branch_net.input_proj.0.bias: 0.2564\n",
            "      Shape: [32], Elements: 32\n",
            "      Mean: 0.000000, Std: 0.045325\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 683/1280 [01:39<01:24,  7.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 681 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5854\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000002, Std: 0.010562\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4919\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000033, Std: 0.015373\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3221\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000003, Std: 0.010065\n",
            "  âœ… 4. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2497\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000010, Std: 0.005518\n",
            "  âœ… 5. trunk_net.net.16.weight: 0.2283\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000397, Std: 0.007124\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 685/1280 [01:39<01:25,  6.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 683 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5947\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000003, Std: 0.010730\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4678\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000026, Std: 0.014620\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.2926\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000009, Std: 0.009145\n",
            "  âœ… 4. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2344\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000009, Std: 0.005179\n",
            "  âœ… 5. trunk_net.net.16.weight: 0.2340\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000422, Std: 0.007302\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 684 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5928\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000002, Std: 0.010695\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4535\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000030, Std: 0.014171\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3313\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000007, Std: 0.010354\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2554\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000380, Std: 0.007971\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2249\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000003, Std: 0.004970\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 687/1280 [01:40<01:25,  6.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 685 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.6011\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000002, Std: 0.010845\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4619\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000005, Std: 0.014433\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3153\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000001, Std: 0.009853\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2405\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000494, Std: 0.007500\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2368\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000002, Std: 0.005233\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 686 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5585\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000003, Std: 0.010076\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4878\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000025, Std: 0.015244\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3617\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000064, Std: 0.011303\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2832\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000804, Std: 0.008815\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2588\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000010, Std: 0.005718\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 690/1280 [01:40<01:22,  7.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 688 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5505\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: -0.000001, Std: 0.009932\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4257\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000005, Std: 0.013303\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.4153\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000031, Std: 0.012979\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.3219\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000643, Std: 0.010038\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2124\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000003, Std: 0.004694\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 689 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5883\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000003, Std: 0.010614\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4777\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000034, Std: 0.014929\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3035\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000018, Std: 0.009483\n",
            "  âœ… 4. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2486\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000049, Std: 0.005492\n",
            "  âœ… 5. trunk_net.net.16.weight: 0.2362\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000209, Std: 0.007379\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 692/1280 [01:40<01:26,  6.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 690 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.4925\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000002, Std: 0.008886\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.4873\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000012, Std: 0.015227\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3813\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000008, Std: 0.011914\n",
            "  âœ… 4. trunk_net.net.16.weight: 0.2677\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.001356, Std: 0.008255\n",
            "  âœ… 5. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2472\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: 0.000020, Std: 0.005463\n",
            "============================================================\n",
            "\n",
            "ðŸ” === Gradient Analysis - Epoch 0, Batch 691 ===\n",
            "Total Gradient Norm: 1.000000\n",
            "âœ… Gradient norm is healthy\n",
            "\n",
            "Top 5 layers by gradient norm (out of 41 total):\n",
            "  âœ… 1. branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: 0.5148\n",
            "      Shape: [96, 32], Elements: 3072\n",
            "      Mean: 0.000003, Std: 0.009288\n",
            "  âœ… 2. branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: 0.5063\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: 0.000011, Std: 0.015823\n",
            "  âœ… 3. branch_net.output_proj.2.weight: 0.3425\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000067, Std: 0.010702\n",
            "  âœ… 4. branch_net.transformer_encoder.layers.0.linear2.weight: 0.2773\n",
            "      Shape: [32, 64], Elements: 2048\n",
            "      Mean: -0.000011, Std: 0.006128\n",
            "  âœ… 5. trunk_net.net.16.weight: 0.2464\n",
            "      Shape: [32, 32], Elements: 1024\n",
            "      Mean: -0.000855, Std: 0.007651\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 694/1280 [01:41<01:27,  6.67it/s]"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from comet_ml import start\n",
        "from comet_ml.integration.pytorch import log_model\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Assuming OptimizedDeepONet, OptimizedTrainer, ExtendedEarlyStopping, OperatorDatasetStandarization\n",
        "# and other utility functions (compute_gradient_stats, print_gradient_summary, get_stable_hyperparameters)\n",
        "# are available in the scope or imported.\n",
        "\n",
        "# Hyperparameters (these will now be primarily driven by get_stable_hyperparameters)\n",
        "hidden_dim = 32\n",
        "latent_dim = 32\n",
        "batch_size = 32\n",
        "epochs = 1000\n",
        "portfolio_feature_dim = 3\n",
        "\n",
        "PORT_LEN = 200\n",
        "PORT_SAMPLE_SIZE = 51200\n",
        "FEED_ST_LEN_EACH_PORT = 50\n",
        "SAMPLE_SIZE_SCALAR = 20\n",
        "# REMOVED: LAMBDA_DERIV = 0.1 (it's now part of hyperparameters)\n",
        "\n",
        "\n",
        "# Comet Experiment Setup\n",
        "experiment = start(api_key=\"iatWnXT4JyBtDQhn7OfgISQoF\", project_name=\"option-portfolio-encoder-decoder\", workspace=\"satyabratkumarsingh\")\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def main():\n",
        "    # Retrieve hyperparameters\n",
        "    hparams = get_stable_hyperparameters()\n",
        "    experiment.log_parameters(hparams) # Log all hparams to Comet\n",
        "\n",
        "    # Initialize model\n",
        "    deeponet_model = OptimizedDeepONet(portfolio_feature_dim=portfolio_feature_dim, hidden_dim=hidden_dim, latent_dim=latent_dim, use_induced=False).to(DEVICE)\n",
        "\n",
        "    # Initialize optimized trainer with explicit hyperparameters\n",
        "    trainer = OptimizedTrainer(\n",
        "        deeponet_model,\n",
        "        device=DEVICE,\n",
        "        learning_rate=hparams[\"learning_rate\"],\n",
        "        lambda_deriv_weight=hparams[\"lambda_deriv\"],\n",
        "        weight_decay=hparams[\"weight_decay\"], # Pass weight_decay as well for consistency\n",
        "        # You can add other configurable hparams from get_stable_hyperparameters here\n",
        "    )\n",
        "\n",
        "    # Assuming dataset has been created\n",
        "    dataset = OperatorDatasetStandarization(num_samples=PORT_SAMPLE_SIZE, portfolio_size=PORT_LEN, num_samples_S_T=FEED_ST_LEN_EACH_PORT, is_fitting_mode=False)\n",
        "\n",
        "    # Split dataset\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    val_size = (val_size // batch_size) * batch_size  # Round to nearest multiple of batch_size\n",
        "    train_size = len(dataset) - val_size\n",
        "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    # Create DataLoader for both train and validation datasets\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Early stopping and learning rate scheduler setup\n",
        "    best_val_total_loss = float('inf')  # Track best validation loss for early stopping\n",
        "    early_stopping = ExtendedEarlyStopping(patience=hparams[\"early_stopping_patience\"], min_delta=0.0005) # Use hparams patience\n",
        "    # REMOVED: lambda_deriv = LAMBDA_DERIV # No longer needed, trainer uses its internal stored value\n",
        "    plateau_scheduler = optim.lr_scheduler.ReduceLROnPlateau(trainer.optimizer, mode='min', factor=0.7, patience=10, verbose=True)\n",
        "\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        train_epoch_total_losses = []\n",
        "        train_epoch_cashflow_losses = []\n",
        "        train_epoch_deriv_losses = []\n",
        "\n",
        "        trainer.update_scale(epoch)\n",
        "        trainer.model.train()\n",
        "\n",
        "        for batch_idx, (portfolio_real, s_t_real, cashflows_real, derivs_real) in enumerate(tqdm(train_loader, desc=f\"Training Epoch {epoch}\", leave=False)):\n",
        "            portfolio_real = portfolio_real.to(torch.float32).to(DEVICE)\n",
        "            cashflows_real = cashflows_real.to(torch.float32).to(DEVICE)\n",
        "            s_t_real = s_t_real.to(torch.float32).to(DEVICE)\n",
        "            derivs_real = derivs_real.to(torch.float32).to(DEVICE)\n",
        "\n",
        "\n",
        "            # Get all loss components from train_step\n",
        "            total_loss, cashflow_loss, deriv_loss = trainer.train_step(\n",
        "                portfolio=portfolio_real,\n",
        "                S_T=s_t_real,\n",
        "                cashflow=cashflows_real,\n",
        "                true_derivative=derivs_real, # This is the true derivative for loss comparison\n",
        "                batch_idx=batch_idx,\n",
        "                experiment=experiment\n",
        "            )\n",
        "            train_epoch_total_losses.append(total_loss)\n",
        "            train_epoch_cashflow_losses.append(cashflow_loss)\n",
        "            train_epoch_deriv_losses.append(deriv_loss)\n",
        "\n",
        "            # Log individual batch training losses\n",
        "            experiment.log_metric(\"training_total_loss_batch\", total_loss, step=epoch * len(train_loader) + batch_idx)\n",
        "            experiment.log_metric(\"training_cashflow_loss_batch\", cashflow_loss, step=epoch * len(train_loader) + batch_idx)\n",
        "            experiment.log_metric(\"training_deriv_loss_batch\", deriv_loss, step=epoch * len(train_loader) + batch_idx)\n",
        "\n",
        "        # Average epoch losses for training\n",
        "        avg_train_total_loss = np.mean(train_epoch_total_losses)\n",
        "        avg_train_cashflow_loss = np.mean(train_epoch_cashflow_losses)\n",
        "        avg_train_deriv_loss = np.mean(train_epoch_deriv_losses)\n",
        "\n",
        "        # Log average training losses for the epoch\n",
        "        experiment.log_metric(\"training_total_loss_epoch\", avg_train_total_loss, epoch=epoch)\n",
        "        experiment.log_metric(\"training_cashflow_loss_epoch\", avg_train_cashflow_loss, epoch=epoch)\n",
        "        experiment.log_metric(\"training_deriv_loss_epoch\", avg_train_deriv_loss, epoch=epoch)\n",
        "\n",
        "        # Validation loop\n",
        "        trainer.model.eval()\n",
        "        val_epoch_total_losses = []\n",
        "        val_epoch_cashflow_losses = []\n",
        "        val_epoch_deriv_losses = []\n",
        "\n",
        "        with torch.no_grad(): # Outer no_grad is for overall validation efficiency\n",
        "            for batch_idx, (portfolio_real, s_t_real, cashflows_real, derivs_real) in enumerate(tqdm(val_loader, desc=f\"Validation Epoch {epoch}\", leave=False)):\n",
        "\n",
        "                portfolio_real = portfolio_real.to(torch.float32).to(DEVICE)\n",
        "                cashflows_real = cashflows_real.to(torch.float32).to(DEVICE)\n",
        "                s_t_real = s_t_real.to(torch.float32).to(DEVICE) # Ensure S_T is float32\n",
        "                derivs_real = derivs_real.to(torch.float32).to(DEVICE)\n",
        "\n",
        "                # val_step now implicitly calculates the derivative\n",
        "                val_total_loss, val_cashflow_loss, val_deriv_loss = trainer.val_step(\n",
        "                    portfolio=portfolio_real,\n",
        "                    S_T=s_t_real,\n",
        "                    cashflow=cashflows_real,\n",
        "                    derivative=derivs_real, # This is the true derivative for loss comparison\n",
        "                )\n",
        "\n",
        "\n",
        "                val_epoch_total_losses.append(val_total_loss)\n",
        "                val_epoch_cashflow_losses.append(val_cashflow_loss)\n",
        "                val_epoch_deriv_losses.append(val_deriv_loss)\n",
        "\n",
        "        # Average validation losses for the epoch\n",
        "        avg_val_total_loss = np.mean(val_epoch_total_losses)\n",
        "        avg_val_cashflow_loss = np.mean(val_epoch_cashflow_losses)\n",
        "        avg_val_deriv_loss = np.mean(val_epoch_deriv_losses)\n",
        "\n",
        "        # Log validation losses for the epoch\n",
        "        experiment.log_metric(\"validation_total_loss_epoch\", avg_val_total_loss, epoch=epoch)\n",
        "        experiment.log_metric(\"validation_cashflow_loss_epoch\", avg_val_cashflow_loss, epoch=epoch)\n",
        "        experiment.log_metric(\"validation_deriv_loss_epoch\", avg_val_deriv_loss, epoch=epoch)\n",
        "\n",
        "        # Step the plateau scheduler based on validation total loss\n",
        "        plateau_scheduler.step(avg_val_total_loss)\n",
        "\n",
        "        # Progress reporting\n",
        "        if epoch % 10 == 0:\n",
        "            current_lr = trainer.optimizer.param_groups[0]['lr']\n",
        "            print(f'Epoch [{epoch}/{epochs}], Train Total Loss: {avg_train_total_loss:.6f}, Val Total Loss: {avg_val_total_loss:.6f}, '\n",
        "                  f'Train CF Loss: {avg_train_cashflow_loss:.6f}, Val CF Loss: {avg_val_cashflow_loss:.6f}, '\n",
        "                  f'Train Deriv Loss: {avg_train_deriv_loss:.6f}, Val Deriv Loss: {avg_val_deriv_loss:.6f}')\n",
        "            print(f'Current Learning Rate: {current_lr:.8f}')\n",
        "\n",
        "        # Save checkpoint every 50 epochs\n",
        "        if epoch % 50 == 0 and epoch > 0:\n",
        "            checkpoint_path = f'/content/drive/MyDrive/Ucl/checkpoint_epoch_{epoch}_V2.pt'\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': trainer.model.state_dict(),\n",
        "                'optimizer_state_dict': trainer.optimizer.state_dict(),\n",
        "                'scheduler_state_dict': trainer.scheduler.state_dict(),\n",
        "                'train_total_loss': avg_train_total_loss,\n",
        "                'val_total_loss': avg_val_total_loss,\n",
        "                'best_val_loss': best_val_total_loss\n",
        "            }, checkpoint_path)\n",
        "            print(f\"Checkpoint saved at epoch {epoch}\")\n",
        "\n",
        "        # Early stopping check (using total loss)\n",
        "        if early_stopping(avg_val_total_loss, trainer.model):\n",
        "            print(f'Early stopping triggered at epoch {epoch}')\n",
        "            save_path = '/content/drive/MyDrive/Ucl/best_deeponet_model_V2.pt'\n",
        "            print(f\"Saving model to drive: {save_path}\")\n",
        "            torch.save(trainer.model.state_dict(), save_path)\n",
        "            print(f\"Model saved to: {save_path}\")\n",
        "            break\n",
        "\n",
        "        if avg_val_total_loss < best_val_total_loss:\n",
        "            best_val_total_loss = avg_val_total_loss\n",
        "\n",
        "    # Save final model even if early stopping doesn't trigger\n",
        "    final_save_path = '/content/drive/MyDrive/Ucl/final_deeponet_model_V2.pt'\n",
        "    torch.save(trainer.model.state_dict(), final_save_path)\n",
        "    print(f\"Final model saved to: {final_save_path}\")\n",
        "\n",
        "    # End the Comet experiment\n",
        "    experiment.end()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7frnRUrtIDw7"
      },
      "source": [
        "#Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "id": "1lnHeRWWQ9eO",
        "outputId": "0996d1b9-b454-4219-8086-c9e3ebac3333"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for OptimizedDeepONet:\n\tsize mismatch for branch_net.input_proj.0.weight: copying a param with shape torch.Size([32, 3]) from checkpoint, the shape in current model is torch.Size([64, 3]).\n\tsize mismatch for branch_net.input_proj.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.input_proj.1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.input_proj.1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([96, 32]) from checkpoint, the shape in current model is torch.Size([192, 64]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.linear1.weight: copying a param with shape torch.Size([64, 32]) from checkpoint, the shape in current model is torch.Size([128, 64]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.linear1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.linear2.weight: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([64, 128]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.linear2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.norm1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.norm1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.norm2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.norm2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.output_proj.0.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.output_proj.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.output_proj.2.weight: copying a param with shape torch.Size([64, 32]) from checkpoint, the shape in current model is torch.Size([128, 64]).\n\tsize mismatch for branch_net.output_proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for trunk_net.net.0.weight: copying a param with shape torch.Size([32, 1]) from checkpoint, the shape in current model is torch.Size([64, 1]).\n\tsize mismatch for trunk_net.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.4.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for trunk_net.net.4.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.5.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.8.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for trunk_net.net.8.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.9.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.9.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.12.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for trunk_net.net.12.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.13.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.13.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.16.weight: copying a param with shape torch.Size([64, 32]) from checkpoint, the shape in current model is torch.Size([128, 64]).\n\tsize mismatch for trunk_net.net.16.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-74-3386036759.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Load the state_dict, mapping to the correct device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mdeeponet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mdeeponet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2581\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2582\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2583\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for OptimizedDeepONet:\n\tsize mismatch for branch_net.input_proj.0.weight: copying a param with shape torch.Size([32, 3]) from checkpoint, the shape in current model is torch.Size([64, 3]).\n\tsize mismatch for branch_net.input_proj.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.input_proj.1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.input_proj.1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([96, 32]) from checkpoint, the shape in current model is torch.Size([192, 64]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.linear1.weight: copying a param with shape torch.Size([64, 32]) from checkpoint, the shape in current model is torch.Size([128, 64]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.linear1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.linear2.weight: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([64, 128]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.linear2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.norm1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.norm1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.norm2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.transformer_encoder.layers.0.norm2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.output_proj.0.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.output_proj.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for branch_net.output_proj.2.weight: copying a param with shape torch.Size([64, 32]) from checkpoint, the shape in current model is torch.Size([128, 64]).\n\tsize mismatch for branch_net.output_proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for trunk_net.net.0.weight: copying a param with shape torch.Size([32, 1]) from checkpoint, the shape in current model is torch.Size([64, 1]).\n\tsize mismatch for trunk_net.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.4.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for trunk_net.net.4.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.5.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.8.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for trunk_net.net.8.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.9.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.9.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.12.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for trunk_net.net.12.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.13.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.13.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for trunk_net.net.16.weight: copying a param with shape torch.Size([64, 32]) from checkpoint, the shape in current model is torch.Size([128, 64]).\n\tsize mismatch for trunk_net.net.16.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128])."
          ]
        }
      ],
      "source": [
        "# Load the trained model\n",
        "\n",
        "hidden_dim = 64\n",
        "latent_dim = 128\n",
        "batch_size = 128\n",
        "epochs = 1000\n",
        "portfolio_feature_dim = 3\n",
        "\n",
        "PORT_LEN = 200\n",
        "PORT_SAMPLE_SIZE = 25600\n",
        "FEED_ST_LEN_EACH_PORT = 20\n",
        "SAMPLE_SIZE_SCALAR = 20\n",
        "LAMBDA_DERIV = 0.1\n",
        "\n",
        "\n",
        "\n",
        "final_save_path = '/content/drive/MyDrive/Ucl/'\n",
        "model_path = final_save_path + 'best_deeponet_model_V2.pt' # Construct the full path to the model file\n",
        "\n",
        "deeponet_model = OptimizedDeepONet(portfolio_feature_dim=portfolio_feature_dim, hidden_dim=hidden_dim, latent_dim=latent_dim).to(DEVICE)\n",
        "\n",
        "# Load the state_dict, mapping to the correct device\n",
        "deeponet_model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "\n",
        "deeponet_model.eval()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dataset = OperatorDatasetStandarization(num_samples=1, portfolio_size=100, num_samples_S_T=20)\n",
        "portfolio, S_T_i, true_cashflows, derivative_i = dataset[0]\n",
        "\n",
        "\n",
        "# Predict cashflows with the model\n",
        "with torch.no_grad():\n",
        "    predicted_cashflows = deeponet_model(portfolio, S_T_i)\n",
        "\n",
        "s_t_values_sorted, indices = torch.sort(S_T_i, dim=0)\n",
        "\n",
        "# Debugging prints\n",
        "print('=====Portfolio=====')\n",
        "print(portfolio)\n",
        "print('=====S_T Sorted=====')\n",
        "print(s_t_values_sorted)\n",
        "print('=====True Cashflows=====')\n",
        "print(true_cashflows)\n",
        "print('=====Predicted Cashflows=====')\n",
        "print(predicted_cashflows)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(s_t_values_sorted.cpu().numpy(), true_cashflows, label='True Cashflow', color='blue')\n",
        "plt.plot(s_t_values_sorted.cpu().numpy(), predicted_cashflows, label='Predicted Cashflow', color='orange', linestyle='--')\n",
        "plt.xlabel('S_T (Absolute Value)')\n",
        "plt.ylabel('Cashflow')\n",
        "plt.title('True vs. Predicted Cashflow for a Single Portfolio (Sorted S_T)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBH_Vr84EjlY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyN9C2ik24u9+Ei0BPG9sIO9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}